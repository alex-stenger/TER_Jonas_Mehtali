{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbfd55-aab0-4688-bb39-68f9754efc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.dataset import SegmentationDataSet\n",
    "from utils.printer import source_printer\n",
    "from utils.printer import target_printer\n",
    "from utils.model import UNet\n",
    "from utils.model import YNet\n",
    "from utils.model import Recons_net\n",
    "from utils.utils import preprocessing\n",
    "from utils.utils import IoU\n",
    "from utils.utils import postprocessing\n",
    "from utils.utils import dice_coeff\n",
    "from utils.utils import multiclass_dice_coeff\n",
    "from utils.utils import dice_loss\n",
    "from utils.utils import smooth\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0109f-3991-4931-ad21-53372b647177",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = str(datetime.now()).split(' ')[0]\n",
    "heure = str(datetime.now()).split(' ')[1].split('.')[0]\n",
    "\n",
    "# Root directory for dataset\n",
    "##Refaire nos data folder et tout pour que ce soit \n",
    "#au format demandé par le dataloader\n",
    "dataroot_source = \"data/IGBMC_LW4_diversifie/patches/\"\n",
    "train_list_source_path = \"data/IGBMC_LW4_diversifie/patches/train_5000.txt\"\n",
    "\n",
    "\n",
    "source_name = dataroot_source.split(\"/\")[1].split(\"_\")[1]\n",
    "\n",
    "print(source_name)\n",
    "\n",
    "#Some other roots\n",
    "#Where to save plots, networks weights and final lists values\n",
    "saving_folder = \"U-Net\"+dataroot_source.split('/')[3]+\"_\"+source_name+\"_\"+date+\"_\"+heure\n",
    "\n",
    "\n",
    "os.mkdir(saving_folder) #We create this folder (only if it doesn't exists) to save weights of the training at some keys epoch\n",
    "os.mkdir(saving_folder+\"/loss-dice_listes\")\n",
    "os.mkdir(saving_folder+\"/newtork_weigths\")\n",
    "os.mkdir(saving_folder+\"/training_monitoring\")\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training (low batch_size if there are memory issues)\n",
    "batch_size = 5\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size_source = 256\n",
    "image_size_target = 256 \n",
    "image_size_discriminator = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 2\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 200\n",
    "\n",
    "# Learning rate for optimizers\n",
    "learning_rate_unet=1e-5\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "#some unet variable\n",
    "amp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e433fd-8bfa-4f6a-a920-d7b232b35f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of gpus :\", torch.cuda.device_count())\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "print(\"device ID\", device)  #On regarde l'identifiant du GPU ou CPU sur lequel on travaille\n",
    "print(\"nom du GPU\", torch.cuda.get_device_name(device)) #On vérifie son \"nom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d5318a-4bd2-4900-b6b5-464247afd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = open(saving_folder+\"/log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39842e-9120-4604-abfa-593528318a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.write(\"dataroot_source :\"+dataroot_source+\"\\n\")\n",
    "log_file.write(\"train_list_source :\"+train_list_source_path+\"\\n\")\n",
    "log_file.write(\"batch_size=\"+str(batch_size)+\"\\n\")\n",
    "log_file.write(\"learning_rate_unet=\"+str(learning_rate_unet)+\"\\n\")\n",
    "log_file.write(\"num_epoch=\"+str(num_epochs)+\"\\n\")\n",
    "log_file.write(\"nc=\"+str(nc)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17e86a-d326-4744-92cf-49a688bafc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des images et masques de i3\n",
    "dataset_source = SegmentationDataSet(root=dataroot_source,\n",
    "                                     list_path=train_list_source_path)\n",
    "\n",
    "# Dataloader pour i3\n",
    "dataloader_source = torch.utils.data.DataLoader(dataset_source, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "#On affiche quelques exemple du batch pour vérifier qu'on a bien importé les données\n",
    "source_printer(dataloader_source=dataloader_source, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85441e62-1331-4b5c-9c6f-18fb34c280e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(n_channels=3, n_classes=2, bilinear=False) #bilinear set by default to False here\n",
    "unet.to(device=device)\n",
    "\n",
    "#On revérifie qu'on tourne bien le réseau de neuronnes sur le GPU\n",
    "print(\"We are running U-Net on :\", torch.cuda.get_device_name(device))\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    unet = nn.DataParallel(unet, list(range(ngpu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6593a4c-7fc5-4682-b668-e32aeddb41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss, optimizers and friends for UNet\n",
    "\n",
    "criterion_unet = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler_params = dict(max_lr=learning_rate_unet, epochs=num_epochs, steps_per_epoch=len(dataloader_source))\n",
    "optimizer_global = optim.AdamW(list(unet.parameters()))\n",
    "scheduler_global = optim.lr_scheduler.OneCycleLR(optimizer_global, **scheduler_params)  # goal: maximize Dice score\n",
    "grad_scaler_global = torch.cuda.amp.GradScaler(enabled=amp)  #Default parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd44ce-9e38-4abc-b6c9-18003443de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.write(\"dataroot_source :\"+dataroot_source+\"\\n\")\n",
    "log_file.write(\"train_list_source :\"+train_list_source_path+\"\\n\")\n",
    "log_file.write(\"batch_size=\"+str(batch_size)+\"\\n\")\n",
    "log_file.write(\"learning_rate_unet=\"+str(learning_rate_unet)+\"\\n\")\n",
    "log_file.write(\"num_epoch=\"+str(num_epochs)+\"\\n\")\n",
    "log_file.write(\"nc=\"+str(nc)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9bac1-b6d3-43a2-b5d9-76ea9bab4ce3",
   "metadata": {},
   "source": [
    "## Ici on fait l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824215d-c494-45b4-bbde-6511ad032b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "n_train = len(dataset_source)\n",
    "print(n_train)\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "source_dice = []\n",
    "intervalle = []\n",
    "\n",
    "L_seg_list = []\n",
    "\n",
    "L_s_list = []\n",
    "\n",
    "compteur_plot = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    dice_score_target = []\n",
    "    epoch_loss = 0\n",
    "    cpt_it = 0\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='img') as pbar:\n",
    "\n",
    "        for batch_source in dataloader_source : \n",
    "            \n",
    "            unet.train()\n",
    "            \n",
    "            cpt_it += 1\n",
    "            \n",
    "            images_source = batch_source ['image']\n",
    "            true_masks_source = batch_source['mask']\n",
    "\n",
    "            assert images_source.shape[1] == unet.n_channels\n",
    "\n",
    "\n",
    "            images_source = images_source.to(device=device, dtype=torch.float32)\n",
    "            true_masks_source = true_masks_source.to(device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "            #Pass Data Trought Unet before optimizing everything\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=amp):\n",
    "                masks_source_pred = unet(images_source)\n",
    "                \n",
    "\n",
    "\n",
    "            ############################\n",
    "            # (2) Update Unet network: minimize Lseg(Xs)\n",
    "            ###########################\n",
    "\n",
    "\n",
    "            #D'abbord, on sort l'output du U-Net sur une image source (on a le mask)\n",
    "            # En gros, ici on va sortir la Loss Lseg(Xs)\n",
    "            with torch.cuda.amp.autocast(enabled=amp):\n",
    "                L_seg = criterion_unet(masks_source_pred, true_masks_source[:,0,:,:]) \\\n",
    "                           + dice_loss(F.softmax(masks_source_pred, dim=1).float(),\n",
    "                                       F.one_hot(true_masks_source[:,0,:,:], unet.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                                       multiclass=True)\n",
    "\n",
    "            \n",
    "            L_global = L_seg\n",
    "            \n",
    "            grad_scaler_global.scale(L_global).backward()\n",
    "            grad_scaler_global.step(optimizer_global)\n",
    "            grad_scaler_global.update()\n",
    "            \n",
    "            \n",
    "            ###########################################################\n",
    "            # Evaluation on the Training Set\n",
    "            ###########################################################\n",
    "            \n",
    "            unet.eval()\n",
    "\n",
    "            with torch.no_grad() :\n",
    "                source_pred = unet(images_source)\n",
    "                \n",
    "                dice_source = dice_coeff(F.softmax(source_pred, dim=1).float(), \n",
    "                         F.one_hot(true_masks_source[:,0,:,:], unet.n_classes).permute(0, 3, 1, 2).float()).item()\n",
    "                \n",
    "\n",
    "                \n",
    "                source_dice.append(dice_source)\n",
    "                L_seg_list.append(L_global.item())\n",
    "                intervalle.append(compteur_plot)\n",
    "                \n",
    "\n",
    "            \n",
    "            compteur_plot += 1\n",
    "            \n",
    "            pbar.update(images_source.shape[0])\n",
    "            global_step += 1\n",
    "            epoch_loss += L_seg.item()\n",
    "\n",
    "            \n",
    "            pbar.set_postfix(**{'loss (batch)': L_seg.item()})\n",
    "            #pbar.set_postfix(**{'dice target': dice_target})\n",
    "            \n",
    "        #print(\"whole epoch target dice mean :\", sum(dice_score_target)/cpt_it)\n",
    "        if (epoch%3==0) : #and epoch != 0 :\n",
    "            torch.save(unet.state_dict(), saving_folder+\"/newtork_weigths/UNet_\"+str(epoch)+\"_epochs.pth\")\n",
    "            #torch.save(ynet.state_dict(), saving_folder+\"/newtork_weigths/recons_net_Cell_Seg_UDA_with_recons_4000-4000_\"+str(epoch)+\"_epochs.pth\")\n",
    "            \n",
    "            source_smooth = smooth(source_dice, 0.99)\n",
    "            \n",
    "            L_seg_smooth = smooth(L_seg_list, 0.99)\n",
    "            \n",
    "            \n",
    "\n",
    "            plt.figure(0)\n",
    "            plt.clf()\n",
    "            plt.plot(intervalle, source_smooth, 'b-', label='source')\n",
    "            plt.title(\"dice score among training, smoothed\")\n",
    "            plt.xlabel(\"iterations\")\n",
    "            plt.ylabel(\"dice score (0 to 1)\")\n",
    "            plt.legend()\n",
    "            plt.savefig(saving_folder+\"/training_monitoring/dice_score_epoch_\"+str(epoch)+\".png\")\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure(1)\n",
    "            plt.clf()\n",
    "            plt.plot(intervalle, L_seg_smooth, 'r-', label='L_global')\n",
    "            plt.xlabel(\"nb itérations\")\n",
    "            plt.ylabel(\"Loss Value\")\n",
    "            plt.title(\"Loss Monitoring among training\")\n",
    "            plt.legend()\n",
    "            plt.savefig(saving_folder+\"/training_monitoring/L_seg_\"+str(epoch)+\"_epoch.png\")\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
